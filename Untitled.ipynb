{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant modules to be used later\n",
    "import urllib\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import sys\n",
    "import cntk as C\n",
    "\n",
    "try:\n",
    "    from urllib.request import urlretrieve, urlopen\n",
    "except ImportError:\n",
    "    from urllib import urlretrieve, urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the right target device when this notebook is being tested:\n",
    "if 'TEST_DEVICE' in os.environ:\n",
    "    if os.environ['TEST_DEVICE'] == 'cpu':\n",
    "        C.device.try_set_default_device(C.device.cpu())\n",
    "    else:\n",
    "        C.device.try_set_default_device(C.device.gpu(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "isFast = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the data path for testing\n",
    "# Check for an environment variable defined in CNTK's test infrastructure\n",
    "envvar = 'CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY'\n",
    "def is_test(): return envvar in os.environ\n",
    "\n",
    "if is_test():\n",
    "    test_data_path_base = os.path.join(os.environ[envvar], \"Tutorials\", \"data\")\n",
    "    test_data_dir = os.path.join(test_data_path_base, \"BerkeleySegmentationDataset\")\n",
    "    test_data_dir = os.path.normpath(test_data_dir)\n",
    "\n",
    "# Default directory in a local folder where the tutorial is run\n",
    "data_dir = os.path.join(\"data\", \"BerkeleySegmentationDataset\")\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "#folder with images to be evaluated\n",
    "example_folder = os.path.join(data_dir, \"example_images\")\n",
    "if not os.path.exists(example_folder):\n",
    "    os.makedirs(example_folder)\n",
    "\n",
    "#folders with resulting images\n",
    "results_folder = os.path.join(data_dir, \"example_results\")\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(images_dir, link):\n",
    "    #Open the url\n",
    "    images_html = urlopen(link).read().decode('utf-8')\n",
    "\n",
    "    #looking for .jpg images whose names are numbers\n",
    "    image_regex = \"[0-9]+.jpg\"\n",
    "\n",
    "    #remove duplicates\n",
    "    image_list = set(re.findall(image_regex, images_html))\n",
    "    print(\"Starting download...\")\n",
    "\n",
    "    num = 0\n",
    "\n",
    "    for image in image_list:\n",
    "        num = num + 1\n",
    "        filename = os.path.join(images_dir, image)\n",
    "\n",
    "        if num % 25 == 0:\n",
    "            print(\"Downloading image %d of %d...\" % (num, len(image_list)))\n",
    "        if not os.path.isfile(filename):\n",
    "            urlretrieve(link + image, filename)\n",
    "        else:\n",
    "            print(\"File already exists\", filename)\n",
    "\n",
    "    print(\"Images available at: \", images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download...\n",
      "File already exists data/BerkeleySegmentationDataset/Images/67079.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/33039.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/178054.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/317080.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/69040.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/187003.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/241004.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/302003.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/35058.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/309004.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/176035.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/198023.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/175032.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/25098.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/86016.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/187083.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/86000.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/113016.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/147091.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/138078.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/254054.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/106020.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/58060.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/65132.jpg\n",
      "Downloading image 25 of 300...\n",
      "File already exists data/BerkeleySegmentationDataset/Images/157055.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/181079.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/189003.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/299091.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/27059.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/144067.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/66075.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/361084.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/65010.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/41004.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/155060.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/170054.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/220075.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/277095.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/122048.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/285079.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/145053.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/147021.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/225017.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/229036.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/188063.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/210088.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/268002.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/55075.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/223061.jpg\n",
      "Downloading image 50 of 300...\n",
      "File already exists data/BerkeleySegmentationDataset/Images/22090.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/71046.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/156065.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/181018.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/100080.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/22093.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/23025.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/108005.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/187039.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/23080.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/56028.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/126039.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/196015.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/92059.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/102061.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/242078.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/172032.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/138032.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/160068.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/24004.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/12084.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/21077.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/108082.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/187029.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/253027.jpg\n",
      "Downloading image 75 of 300...\n",
      "File already exists data/BerkeleySegmentationDataset/Images/97033.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/134035.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/176019.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/216041.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/8049.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/14037.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/24077.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/108041.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/153077.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/254033.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/260058.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/376020.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/159045.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/105025.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/109034.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/61086.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/80099.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/181091.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/188005.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/311068.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/164074.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/28096.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/35010.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/314016.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/176039.jpg\n",
      "Downloading image 100 of 300...\n",
      "File already exists data/BerkeleySegmentationDataset/Images/78019.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/112082.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/123074.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/247085.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/239096.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/37073.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/65033.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/311081.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/104022.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/130034.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/117054.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/105053.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/26031.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/3096.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/143090.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/119082.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/385039.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/66053.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/43070.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/106025.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/202012.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/41069.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/45096.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/241048.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/48055.jpg\n",
      "Downloading image 125 of 300...\n",
      "File already exists data/BerkeleySegmentationDataset/Images/274007.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/291000.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/175043.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/126007.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/20008.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/59078.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/187071.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/78004.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/89072.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/134052.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/236037.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/16052.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/38082.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/159008.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/208001.jpg\n",
      "File already exists data/BerkeleySegmentationDataset/Images/2092.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading image 150 of 300...\n",
      "Downloading image 175 of 300...\n",
      "Downloading image 200 of 300...\n",
      "Downloading image 225 of 300...\n",
      "Downloading image 250 of 300...\n",
      "Downloading image 275 of 300...\n",
      "Downloading image 300 of 300...\n",
      "Images available at:  data/BerkeleySegmentationDataset/Images\n",
      "Model directory data/BerkeleySegmentationDataset/PretrainedModels\n",
      "Image directory data/BerkeleySegmentationDataset/Images\n"
     ]
    }
   ],
   "source": [
    "#folder for raw images, before preprocess\n",
    "images_dir = os.path.join(data_dir, \"Images\")\n",
    "if not os.path.exists(images_dir):\n",
    "    os.makedirs(images_dir)\n",
    "\n",
    "#Get the path for pre-trained models and example images\n",
    "if is_test():\n",
    "    print(\"Using cached test data\")\n",
    "    models_dir = os.path.join(test_data_dir, \"PretrainedModels\")\n",
    "    images_dir = os.path.join(test_data_dir, \"Images\")\n",
    "else:\n",
    "    models_dir = os.path.join(data_dir, \"PretrainedModels\")\n",
    "    if not os.path.exists(models_dir):\n",
    "        os.makedirs(models_dir)\n",
    "\n",
    "    images_dir = os.path.join(data_dir, \"Images\")\n",
    "    if not os.path.exists(images_dir):\n",
    "        os.makedirs(images_dir)\n",
    "\n",
    "    #link to BSDS dataset\n",
    "    link = \"https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/BSDS300/html/images/plain/normal/color/\"\n",
    "\n",
    "    download_data(images_dir, link)\n",
    "\n",
    "print(\"Model directory\", models_dir)\n",
    "print(\"Image directory\", images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract 64 x 64 patches from BSDS dataset\n",
    "def prep_64(images_dir, patch_h, patch_w, train64_lr, train64_hr, tests):\n",
    "    if not os.path.exists(train64_lr):\n",
    "        os.makedirs(train64_lr)\n",
    "\n",
    "    if not os.path.exists(train64_hr):\n",
    "        os.makedirs(train64_hr)\n",
    "\n",
    "    if not os.path.exists(tests):\n",
    "        os.makedirs(tests)\n",
    "\n",
    "    k = 0\n",
    "    num = 0\n",
    "\n",
    "    print(\"Creating 64 x 64 training patches and tests from:\", images_dir)\n",
    "\n",
    "    for entry in os.listdir(images_dir):\n",
    "        filename = os.path.join(images_dir, entry)\n",
    "        img = Image.open(filename)\n",
    "        rect = np.array(img)\n",
    "\n",
    "        num = num + 1\n",
    "\n",
    "        if num % 25 == 0:\n",
    "            print(\"Processing image %d of %d...\" % (num, len(os.listdir(images_dir))))\n",
    "\n",
    "        if num % 50 == 0:\n",
    "            img.save(os.path.join(tests, str(num) + \".png\"))\n",
    "            continue\n",
    "\n",
    "        x = 0\n",
    "        y = 0\n",
    "\n",
    "        while(y + patch_h <= img.width):\n",
    "            x = 0\n",
    "            while(x + patch_w <= img.height):\n",
    "                patch = rect[x : x + patch_h, y : y + patch_w]\n",
    "                img_hr = Image.fromarray(patch, 'RGB')\n",
    "\n",
    "                img_lr = img_hr.resize((patch_w // 2, patch_h // 2), Image.ANTIALIAS)\n",
    "                img_lr = img_lr.resize((patch_w, patch_h), Image.BICUBIC)\n",
    "\n",
    "                out_hr = os.path.join(train64_hr, str(k) + \".png\")\n",
    "                out_lr = os.path.join(train64_lr, str(k) + \".png\")\n",
    "\n",
    "                k = k + 1\n",
    "\n",
    "                img_hr.save(out_hr)\n",
    "                img_lr.save(out_lr)\n",
    "\n",
    "                x = x + 42\n",
    "            y = y + 42\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract 224 x 224 and 112 x 112 patches from BSDS dataset\n",
    "def prep_224(images_dir, patch_h, patch_w, train112, train224):\n",
    "    if not os.path.exists(train112):\n",
    "        os.makedirs(train112)\n",
    "\n",
    "    if not os.path.exists(train224):\n",
    "        os.makedirs(train224)\n",
    "\n",
    "    k = 0\n",
    "    num = 0\n",
    "\n",
    "    print(\"Creating 224 x 224 and 112 x 112 training patches from:\", images_dir)\n",
    "\n",
    "    for entry in os.listdir(images_dir):\n",
    "        filename = os.path.join(images_dir, entry)\n",
    "        img = Image.open(filename)\n",
    "        rect = np.array(img)\n",
    "\n",
    "        num = num + 1\n",
    "        if num % 25 == 0:\n",
    "            print(\"Processing image %d of %d...\" % (num, len(os.listdir(images_dir))))\n",
    "\n",
    "        x = 0\n",
    "        y = 0\n",
    "\n",
    "        while(y + patch_h <= img.width):\n",
    "            x = 0\n",
    "            while(x + patch_w <= img.height):\n",
    "                patch = rect[x : x + patch_h, y : y + patch_w]\n",
    "                img_hr = Image.fromarray(patch, 'RGB')\n",
    "\n",
    "                img_lr = img_hr.resize((patch_w // 2, patch_h // 2), Image.ANTIALIAS)\n",
    "\n",
    "                for i in range(4):\n",
    "                    out_hr = os.path.join(train224, str(k) + \".png\")\n",
    "                    out_lr = os.path.join(train112, str(k) + \".png\")\n",
    "\n",
    "                    k = k + 1\n",
    "\n",
    "                    img_hr.save(out_hr)\n",
    "                    img_lr.save(out_lr)\n",
    "\n",
    "                    img_hr = img_hr.transpose(Image.ROTATE_90)\n",
    "                    img_lr = img_lr.transpose(Image.ROTATE_90)\n",
    "\n",
    "                x = x + 64\n",
    "            y = y + 64\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 64 x 64 training patches and tests from: data/BerkeleySegmentationDataset/Images\n",
      "Processing image 25 of 300...\n",
      "Processing image 50 of 300...\n",
      "Processing image 75 of 300...\n",
      "Processing image 100 of 300...\n",
      "Processing image 125 of 300...\n",
      "Processing image 150 of 300...\n",
      "Processing image 175 of 300...\n",
      "Processing image 200 of 300...\n",
      "Processing image 225 of 300...\n",
      "Processing image 250 of 300...\n",
      "Processing image 275 of 300...\n",
      "Processing image 300 of 300...\n",
      "Done!\n",
      "Creating 224 x 224 and 112 x 112 training patches from: data/BerkeleySegmentationDataset/Images\n",
      "Processing image 25 of 300...\n",
      "Processing image 50 of 300...\n",
      "Processing image 75 of 300...\n",
      "Processing image 100 of 300...\n",
      "Processing image 125 of 300...\n",
      "Processing image 150 of 300...\n",
      "Processing image 175 of 300...\n",
      "Processing image 200 of 300...\n",
      "Processing image 225 of 300...\n",
      "Processing image 250 of 300...\n",
      "Processing image 275 of 300...\n",
      "Processing image 300 of 300...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#blurry 64x64 destination\n",
    "train64_lr = os.path.join(data_dir, \"train64_LR\")\n",
    "\n",
    "#original 64x64 destination\n",
    "train64_hr = os.path.join(data_dir, \"train64_HR\")\n",
    "\n",
    "#112x112 patches destination\n",
    "train112 = os.path.join(data_dir, \"train112\")\n",
    "\n",
    "#224x224 pathes destination\n",
    "train224 = os.path.join(data_dir, \"train224\")\n",
    "\n",
    "#tests destination\n",
    "tests = os.path.join(data_dir, \"tests\")\n",
    "\n",
    "#prep\n",
    "prep_64(images_dir, 64, 64, train64_lr, train64_hr, tests)\n",
    "prep_224(images_dir, 224, 224, train112, train224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory is data/BerkeleySegmentationDataset\n"
     ]
    }
   ],
   "source": [
    "#training configuration\n",
    "MINIBATCH_SIZE = 16 if isFast else 64\n",
    "NUM_MINIBATCHES = 200 if isFast else 200000\n",
    "\n",
    "# Ensure the training and test data is generated and available for this tutorial.\n",
    "# We search in two locations for the prepared Berkeley Segmentation Dataset.\n",
    "data_found = False\n",
    "\n",
    "for data_dir in [os.path.join(\"data\", \"BerkeleySegmentationDataset\")]:\n",
    "    train_hr_path = os.path.join(data_dir, \"train64_HR\")\n",
    "    train_lr_path = os.path.join(data_dir, \"train64_LR\")\n",
    "    if os.path.exists(train_hr_path) and os.path.exists(train_lr_path):\n",
    "        data_found = True\n",
    "        break\n",
    "\n",
    "if not data_found:\n",
    "    raise ValueError(\"Please generate the data by completing the first part of this notebook.\")\n",
    "\n",
    "print(\"Data directory is {0}\".format(data_dir))\n",
    "\n",
    "#folders with training data (high and low resolution images) and paths to map files\n",
    "training_folder_HR = os.path.join(data_dir, \"train64_HR\")\n",
    "training_folder_LR = os.path.join(data_dir, \"train64_LR\")\n",
    "MAP_FILE_Y = os.path.join(data_dir, \"train64_HR\", \"map.txt\")\n",
    "MAP_FILE_X = os.path.join(data_dir, \"train64_LR\", \"map.txt\")\n",
    "\n",
    "#image dimensions\n",
    "NUM_CHANNELS = 3\n",
    "IMG_H, IMG_W = 64, 64\n",
    "IMAGE_DIMS = (NUM_CHANNELS, IMG_H, IMG_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a map file from a flat folder\n",
    "import cntk.io.transforms as xforms\n",
    "\n",
    "def create_map_file_from_flatfolder(folder):\n",
    "    file_endings = ['.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG']\n",
    "    map_file_name = os.path.join(folder, \"map.txt\")\n",
    "    with open(map_file_name , 'w') as map_file:\n",
    "        for entry in os.listdir(folder):\n",
    "            filename = os.path.join(folder, entry)\n",
    "            if os.path.isfile(filename) and os.path.splitext(filename)[1] in file_endings:\n",
    "                tempName = '/'.join(filename.split('\\\\'))\n",
    "                tempName = '/'.join(tempName.split('//'))\n",
    "                tempName = '//'.join(tempName.split('/'))\n",
    "                map_file.write(\"{0}\\t0\\n\".format(tempName))\n",
    "    return map_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a minibatch source for training or testing\n",
    "def create_mb_source(map_file, width, height, num_classes = 10, randomize = True):\n",
    "    transforms = [xforms.scale(width = width,  height = height, channels = NUM_CHANNELS, interpolations = 'linear')]\n",
    "    return C.io.MinibatchSource(C.io.ImageDeserializer(map_file, C.io.StreamDefs(\n",
    "        features = C.io.StreamDef(field = 'image', transforms = transforms),\n",
    "        labels = C.io.StreamDef(field = 'label', shape = num_classes))), randomize = randomize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VDSR(h0):\n",
    "    print('Generator input shape: ', h0.shape)\n",
    "\n",
    "    with C.layers.default_options(init = C.he_normal(), activation = C.relu, bias = False):\n",
    "        model = C.layers.Sequential([\n",
    "            C.layers.For(range(18), lambda :\n",
    "                C.layers.Convolution((3, 3), 64, pad = True)),\n",
    "            C.layers.Convolution((3, 3), 3, activation = None, pad = True)\n",
    "        ])\n",
    "\n",
    "    return model(h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computation graph\n",
    "def build_VDSR_graph(lr_image_shape, hr_image_shape, net):\n",
    "    input_dynamic_axes = [C.Axis.default_batch_axis()]\n",
    "    real_X = C.input(lr_image_shape, dynamic_axes = input_dynamic_axes, name = \"real_X\")\n",
    "    real_Y = C.input(hr_image_shape, dynamic_axes = input_dynamic_axes, name = \"real_Y\")\n",
    "\n",
    "    real_X_scaled = real_X/255\n",
    "    real_Y_scaled = real_Y/255\n",
    "\n",
    "    genG = net(real_X_scaled)\n",
    "\n",
    "    #Note: this is where the residual error is calculated and backpropagated through Generator\n",
    "    g_loss_G = IMG_H * IMG_W * C.reduce_mean(C.square(real_Y_scaled - real_X_scaled - genG)) / 2.0\n",
    "\n",
    "    G_optim = C.adam(g_loss_G.parameters, lr = C.learning_rate_schedule(\n",
    "        [(1, 0.1), (1, 0.01), (1, 0.001), (1, 0.0001)], C.UnitType.minibatch, 50000),\n",
    "                   momentum = C.momentum_schedule(0.9), gradient_clipping_threshold_per_sample = 1.0)\n",
    "\n",
    "    G_G_trainer = C.Trainer(genG, (g_loss_G, None), G_optim)\n",
    "\n",
    "    return (real_X, real_Y, genG, real_X_scaled, real_Y_scaled, G_optim, G_G_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "def train(arch, lr_dims, hr_dims, build_graph):\n",
    "    create_map_file_from_flatfolder(training_folder_LR)\n",
    "    create_map_file_from_flatfolder(training_folder_HR)\n",
    "\n",
    "    print(\"Starting training\")\n",
    "\n",
    "    reader_train_X = create_mb_source(MAP_FILE_X, lr_dims[1], lr_dims[2])\n",
    "    reader_train_Y = create_mb_source(MAP_FILE_Y, hr_dims[1], hr_dims[2])\n",
    "    real_X, real_Y, genG, real_X_scaled, real_Y_scaled, G_optim, G_G_trainer = build_graph(lr_image_shape = lr_dims,\n",
    "                                                                                           hr_image_shape = hr_dims, net = arch)\n",
    "\n",
    "    print_frequency_mbsize = 50\n",
    "\n",
    "    pp_G = C.logging.ProgressPrinter(print_frequency_mbsize)\n",
    "\n",
    "    input_map_X = {real_X: reader_train_X.streams.features}\n",
    "    input_map_Y = {real_Y: reader_train_Y.streams.features}\n",
    "\n",
    "    for train_step in range(NUM_MINIBATCHES):\n",
    "\n",
    "        X_data = reader_train_X.next_minibatch(MINIBATCH_SIZE, input_map_X)\n",
    "        batch_inputs_X = {real_X: X_data[real_X].data}\n",
    "\n",
    "        Y_data = reader_train_Y.next_minibatch(MINIBATCH_SIZE, input_map_Y)\n",
    "        batch_inputs_X_Y = {real_X : X_data[real_X].data, real_Y : Y_data[real_Y].data}\n",
    "\n",
    "        G_G_trainer.train_minibatch(batch_inputs_X_Y)\n",
    "        pp_G.update_with_trainer(G_G_trainer)\n",
    "        G_trainer_loss = G_G_trainer.previous_minibatch_loss_average\n",
    "\n",
    "    return (G_G_trainer.model, real_X, real_X_scaled, real_Y, real_Y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Generator input shape:  (3, 64, 64)\n",
      " Minibatch[   1-  50]: loss = 996136808.496877 * 800;\n",
      " Minibatch[  51- 100]: loss = 3.715780 * 800;\n",
      " Minibatch[ 101- 150]: loss = 3.699257 * 800;\n",
      " Minibatch[ 151- 200]: loss = 3.780041 * 800;\n"
     ]
    }
   ],
   "source": [
    "VDSR_model, real_X, real_X_scaled, real_Y, real_Y_scaled = train(VDSR, IMAGE_DIMS, IMAGE_DIMS, build_VDSR_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DRRN architecture and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic DRRN block\n",
    "def DRRN_basic_block(inp, num_filters):\n",
    "    c1 = C.layers.Convolution((3, 3), num_filters, init = C.he_normal(), pad = True, bias = False)(inp)\n",
    "    c1 = C.layers.BatchNormalization(map_rank = 1)(c1)\n",
    "    return c1\n",
    "\n",
    "def DRRN(h0):\n",
    "    print('Generator input shape: ', h0.shape)\n",
    "\n",
    "    with C.layers.default_options(init = C.he_normal(), activation = C.relu, bias = False):\n",
    "        h1 = C.layers.Convolution((3, 3), 128, pad = True)(h0)\n",
    "        h2 = DRRN_basic_block(h1, 128)\n",
    "        h3 = DRRN_basic_block(h2, 128)\n",
    "        h4 = h1 + h3\n",
    "\n",
    "        for _ in range(8):\n",
    "            h2 = DRRN_basic_block(h4, 128)\n",
    "            h3 = DRRN_basic_block(h2, 128)\n",
    "            h4 = h1 + h3\n",
    "\n",
    "        h_out = C.layers.Convolution((3, 3), 3, activation = None, pad = True)(h4)\n",
    "\n",
    "        return h_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Generator input shape:  (3, 64, 64)\n",
      " Minibatch[   1-  50]: loss = 2447.199656 * 800;\n",
      " Minibatch[  51- 100]: loss = 131.911629 * 800;\n",
      " Minibatch[ 101- 150]: loss = 118.163875 * 800;\n",
      " Minibatch[ 151- 200]: loss = 105.169116 * 800;\n"
     ]
    }
   ],
   "source": [
    "DRRN_model, real_X, real_X_scaled, real_Y, real_Y_scaled = train(DRRN, IMAGE_DIMS, IMAGE_DIMS, build_VDSR_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRResNet super-resolution model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory is data/BerkeleySegmentationDataset\n"
     ]
    }
   ],
   "source": [
    "#training configuration\n",
    "MINIBATCH_SIZE = 8 if isFast else 16\n",
    "NUM_MINIBATCHES = 200 if isFast else 1000000\n",
    "\n",
    "# Ensure the training and test data is generated and available for this tutorial.\n",
    "# We search in two locations for the prepared Berkeley Segmentation Dataset.\n",
    "data_found = False\n",
    "\n",
    "for data_dir in [os.path.join(\"data\", \"BerkeleySegmentationDataset\")]:\n",
    "    train_hr_path = os.path.join(data_dir, \"train224\")\n",
    "    train_lr_path = os.path.join(data_dir, \"train112\")\n",
    "    if os.path.exists(train_hr_path) and os.path.exists(train_lr_path):\n",
    "        data_found = True\n",
    "        break\n",
    "\n",
    "if not data_found:\n",
    "    raise ValueError(\"Please generate the data by completing the first part of this notebook.\")\n",
    "\n",
    "print(\"Data directory is {0}\".format(data_dir))\n",
    "\n",
    "#folders with training data (high and low resolution images) and paths to map files\n",
    "training_folder_HR = os.path.join(data_dir, \"train224\")\n",
    "training_folder_LR = os.path.join(data_dir, \"train112\")\n",
    "MAP_FILE_Y = os.path.join(data_dir, \"train224\", \"map.txt\")\n",
    "MAP_FILE_X = os.path.join(data_dir, \"train112\", \"map.txt\")\n",
    "\n",
    "#image dimensions\n",
    "NUM_CHANNELS = 3\n",
    "LR_H, LR_W, HR_H, HR_W = 112, 112, 224, 224\n",
    "LR_IMAGE_DIMS = (NUM_CHANNELS, LR_H, LR_W)\n",
    "HR_IMAGE_DIMS = (NUM_CHANNELS, HR_H, HR_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic resnet block\n",
    "def resblock_basic(inp, num_filters):\n",
    "    c1 = C.layers.Convolution((3, 3), num_filters, init = C.he_normal(), pad = True, bias = False)(inp)\n",
    "    c1 = C.layers.BatchNormalization(map_rank = 1)(c1)\n",
    "    c1 = C.param_relu(C.Parameter(c1.shape, init = C.he_normal()), c1)\n",
    "\n",
    "    c2 = C.layers.Convolution((3, 3), num_filters, init = C.he_normal(), pad = True, bias = False)(c1)\n",
    "    c2 = C.layers.BatchNormalization(map_rank = 1)(c2)\n",
    "    return inp + c2\n",
    "\n",
    "def resblock_basic_stack(inp, num_stack_layers, num_filters):\n",
    "    assert (num_stack_layers >= 0)\n",
    "    l = inp\n",
    "    for _ in range(num_stack_layers):\n",
    "        l = resblock_basic(l, num_filters)\n",
    "    return l\n",
    "\n",
    "#SRResNet architecture\n",
    "def SRResNet(h0):\n",
    "    print('Generator inp shape: ', h0.shape)\n",
    "    with C.layers.default_options(init = C.he_normal(), bias = False):\n",
    "\n",
    "        h1 = C.layers.Convolution((9, 9), 64, pad = True)(h0)\n",
    "        h1 = C.param_relu(C.Parameter(h1.shape, init = C.he_normal()), h1)\n",
    "\n",
    "        h2 = resblock_basic_stack(h1, 16, 64)\n",
    "\n",
    "        h3 = C.layers.Convolution((3, 3), 64, activation = None, pad = True)(h2)\n",
    "        h3 = C.layers.BatchNormalization(map_rank = 1)(h3)\n",
    "\n",
    "        h4 = h1 + h3\n",
    "        ##here\n",
    "\n",
    "        h5 = C.layers.ConvolutionTranspose2D((3, 3), 64, pad = True, strides = (2, 2), output_shape = (224, 224))(h4)\n",
    "        h5 = C.param_relu(C.Parameter(h5.shape, init = C.he_normal()), h5)\n",
    "\n",
    "        h6 = C.layers.Convolution((3, 3), 3, pad = True)(h5)\n",
    "\n",
    "        return h6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_SRResNet_graph(lr_image_shape, hr_image_shape, net):\n",
    "    inp_dynamic_axes = [C.Axis.default_batch_axis()]\n",
    "    real_X = C.input(lr_image_shape, dynamic_axes=inp_dynamic_axes, name=\"real_X\")\n",
    "    real_Y = C.input(hr_image_shape, dynamic_axes=inp_dynamic_axes, name=\"real_Y\")\n",
    "\n",
    "    real_X_scaled = real_X/255\n",
    "    real_Y_scaled = real_Y/255\n",
    "\n",
    "    genG = net(real_X_scaled)\n",
    "\n",
    "    G_loss = C.reduce_mean(C.square(real_Y_scaled - genG))\n",
    "\n",
    "    G_optim = C.adam(G_loss.parameters,\n",
    "                    lr = C.learning_rate_schedule([(1, 0.01), (1, 0.001), (98, 0.0001)], C.UnitType.minibatch, 10000),\n",
    "                    momentum = C.momentum_schedule(0.9), gradient_clipping_threshold_per_sample = 1.0)\n",
    "\n",
    "    G_G_trainer = C.Trainer(genG, (G_loss, None), G_optim)\n",
    "\n",
    "    return (real_X, real_Y, genG, real_X_scaled, real_Y_scaled, G_optim, G_G_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Generator inp shape:  (3, 112, 112)\n",
      " Minibatch[   1-  50]: loss = 0.069966 * 400;\n",
      " Minibatch[  51- 100]: loss = 0.011242 * 400;\n",
      " Minibatch[ 101- 150]: loss = 0.007702 * 400;\n",
      " Minibatch[ 151- 200]: loss = 0.006837 * 400;\n"
     ]
    }
   ],
   "source": [
    "SRResNet_model, real_X, real_X_scaled, real_Y, real_Y_scaled = train(SRResNet, LR_IMAGE_DIMS,\n",
    "                                                                     HR_IMAGE_DIMS, build_SRResNet_graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRGAN super-resolution model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic discriminator block\n",
    "def conv_bn_lrelu(inp, filter_size, num_filters, strides = (1, 1), init = C.he_normal()):\n",
    "    r = C.layers.Convolution(filter_size, num_filters, init = init, pad = True, strides = strides, bias = False)(inp)\n",
    "    r = C.layers.BatchNormalization(map_rank = 1)(r)\n",
    "    return C.param_relu(C.constant((np.ones(r.shape) * 0.2).astype(np.float32)), r)\n",
    "\n",
    "#discriminator architecture\n",
    "def discriminator(h0):\n",
    "    print('Discriminator input shape: ', h0.shape)\n",
    "    with C.layers.default_options(init = C.he_normal(), bias = False):\n",
    "        h1 = C.layers.Convolution((3, 3), 64, pad = True)(h0)\n",
    "        h1 = C.param_relu(C.constant((np.ones(h1.shape) * 0.2).astype(np.float32)), h1)\n",
    "\n",
    "        h2 = conv_bn_lrelu(h1, (3, 3), 64, strides = (2, 2))\n",
    "\n",
    "        h3 = conv_bn_lrelu(h2, (3, 3), 128)\n",
    "        h4 = conv_bn_lrelu(h3, (3, 3), 128, strides = (2, 2))\n",
    "\n",
    "        h5 = conv_bn_lrelu(h4, (3, 3), 256)\n",
    "        h6 = conv_bn_lrelu(h5, (3, 3), 256, strides = (2, 2))\n",
    "\n",
    "        h7 = conv_bn_lrelu(h6, (3, 3), 512)\n",
    "        h8 = conv_bn_lrelu(h7, (3, 3), 512, strides = (2, 2))\n",
    "\n",
    "        h9 = C.layers.Dense(1024)(h8)\n",
    "        h10 = C.param_relu(C.constant(0.2, h9.shape), h9)\n",
    "\n",
    "        h11 = C.layers.Dense(1, activation = C.sigmoid)(h10)\n",
    "        return h11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training configuration\n",
    "MINIBATCH_SIZE = 2 if isFast else 4\n",
    "NUM_MINIBATCHES = 200 if isFast else 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gan computation graph\n",
    "def build_GAN_graph(genG, disc, VGG, real_X_scaled, real_Y_scaled, real_Y):\n",
    "    #discriminator on real images\n",
    "    D_real = discriminator(real_Y_scaled)\n",
    "\n",
    "    #discriminator on fake images\n",
    "    D_fake = D_real.clone(method = 'share', substitutions = {real_Y_scaled.output: genG.output})\n",
    "\n",
    "    #VGG on real images\n",
    "    VGG_real = VGG.clone(method = 'share', substitutions = {VGG.arguments[0]: real_Y})\n",
    "\n",
    "    #VGG on fake images\n",
    "    VGG_fake = VGG.clone(method = 'share', substitutions = {VGG.arguments[0]: 255 * genG.output})\n",
    "\n",
    "    #generator loss: GAN loss + MSE loss + perceptual (VGG) loss\n",
    "    G_loss = -C.square(D_fake)*0.001 + C.reduce_mean(C.square(real_Y_scaled - genG)) + C.reduce_mean(C.square(VGG_real - VGG_fake))*0.08\n",
    "\n",
    "    #discriminator loss: loss on real + los on fake images\n",
    "    D_loss = C.square(1.0 - D_real) + C.square(D_fake)\n",
    "\n",
    "    G_optim = C.adam(G_loss.parameters,\n",
    "                    lr = C.learning_rate_schedule([(20, 0.0001), (20, 0.00001)], C.UnitType.minibatch, 5000),\n",
    "                    momentum = C.momentum_schedule(0.9), gradient_clipping_threshold_per_sample = 0.1)\n",
    "\n",
    "    D_optim = C.adam(D_loss.parameters,\n",
    "                    lr = C.learning_rate_schedule([(20, 0.0001), (20, 0.00001)], C.UnitType.minibatch, 5000),\n",
    "                    momentum = C.momentum_schedule(0.9), gradient_clipping_threshold_per_sample = 0.1)\n",
    "\n",
    "    G_trainer = C.Trainer(genG, (G_loss, None), G_optim)\n",
    "\n",
    "    D_trainer = C.Trainer(D_real, (D_loss, None), D_optim)\n",
    "\n",
    "    return (G_trainer, D_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading VGG19 model...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(\"data\", \"BerkeleySegmentationDataset\")\n",
    "if not os.path.exists(data_dir):\n",
    "    data_dir = os.makedirs(data_dir)\n",
    "\n",
    "models_dir = os.path.join(data_dir, \"PretrainedModels\")\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "print(\"Downloading VGG19 model...\")\n",
    "urlretrieve(\"https://www.cntk.ai/Models/Caffe_Converted/VGG19_ImageNet_Caffe.model\",\n",
    "            os.path.join(models_dir, \"VGG19_ImageNet_Caffe.model\"))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GAN(SRResNet_model, real_X, real_X_scaled, real_Y, real_Y_scaled):\n",
    "    print(\"Starting training\")\n",
    "\n",
    "    reader_train_X = create_mb_source(MAP_FILE_X, LR_W, LR_H)\n",
    "    reader_train_Y = create_mb_source(MAP_FILE_Y, HR_W, HR_H)\n",
    "\n",
    "    VGG19 = C.load_model(os.path.join(models_dir, \"VGG19_ImageNet_Caffe.model\"))\n",
    "    print(\"Loaded VGG19 model.\")\n",
    "\n",
    "    layer5_4 = VGG19.find_by_name('relu5_4')\n",
    "    relu5_4  = C.combine([layer5_4.owner])\n",
    "\n",
    "    G_trainer, D_trainer = build_GAN_graph(genG = SRResNet_model, disc = discriminator, VGG = relu5_4,\n",
    "                                           real_X_scaled = real_X_scaled, real_Y_scaled = real_Y_scaled, real_Y = real_Y)\n",
    "\n",
    "    print_frequency_mbsize = 50\n",
    "\n",
    "    print(\"First row is discriminator loss, second row is generator loss:\")\n",
    "    pp_D = C.logging.ProgressPrinter(print_frequency_mbsize)\n",
    "    pp_G = C.logging.ProgressPrinter(print_frequency_mbsize)\n",
    "\n",
    "    inp_map_X = {real_X: reader_train_X.streams.features}\n",
    "    inp_map_Y = {real_Y: reader_train_Y.streams.features}\n",
    "\n",
    "    for train_step in range(NUM_MINIBATCHES):\n",
    "        X_data = reader_train_X.next_minibatch(MINIBATCH_SIZE, inp_map_X)\n",
    "        batch_inps_X = {real_X: X_data[real_X].data}\n",
    "\n",
    "        Y_data = reader_train_Y.next_minibatch(MINIBATCH_SIZE, inp_map_Y)\n",
    "        batch_inps_X_Y = {real_X: X_data[real_X].data, real_Y : Y_data[real_Y].data}\n",
    "\n",
    "        D_trainer.train_minibatch(batch_inps_X_Y)\n",
    "        pp_D.update_with_trainer(D_trainer)\n",
    "        D_trainer_loss = D_trainer.previous_minibatch_loss_average\n",
    "\n",
    "        G_trainer.train_minibatch(batch_inps_X_Y)\n",
    "        pp_G.update_with_trainer(G_trainer)\n",
    "        G_trainer_loss = G_trainer.previous_minibatch_loss_average\n",
    "\n",
    "    model = G_trainer.model\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Loaded VGG19 model.\n",
      "Discriminator input shape:  (3, 224, 224)\n",
      "First row is discriminator loss, second row is generator loss:\n",
      " Minibatch[   1-  50]: loss = 0.604847 * 100;\n",
      " Minibatch[   1-  50]: loss = 0.066153 * 100;\n",
      " Minibatch[  51- 100]: loss = 1.000000 * 100;\n",
      " Minibatch[  51- 100]: loss = 0.008257 * 100;\n",
      " Minibatch[ 101- 150]: loss = 1.000000 * 100;\n",
      " Minibatch[ 101- 150]: loss = 0.005856 * 100;\n",
      " Minibatch[ 151- 200]: loss = 1.000000 * 100;\n",
      " Minibatch[ 151- 200]: loss = 0.005677 * 100;\n"
     ]
    }
   ],
   "source": [
    "SRGAN_model = train_GAN(SRResNet_model, real_X, real_X_scaled, real_Y, real_Y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cntk as C\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import urllib\n",
    "from scipy.misc import imsave\n",
    "\n",
    "try:\n",
    "    from urllib.request import urlretrieve, urlopen\n",
    "except ImportError:\n",
    "    from urllib import urlretrieve, urlopen\n",
    "\n",
    "try:\n",
    "    C.device.try_set_default_device(C.device.gpu(0))\n",
    "except:\n",
    "    print(\"GPU unavailable. Using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the data path for testing\n",
    "# Check for an environment variable defined in CNTK's test infrastructure\n",
    "envvar = 'CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY'\n",
    "def is_test(): return envvar in os.environ\n",
    "\n",
    "if is_test():\n",
    "    test_data_path_base = os.path.join(os.environ[envvar], \"Tutorials\", \"data\")\n",
    "    test_data_dir = os.path.join(test_data_path_base, \"BerkeleySegmentationDataset\")\n",
    "    test_data_dir = os.path.normpath(test_data_dir)\n",
    "\n",
    "\n",
    "#prefer our default path for the data\n",
    "data_dir = os.path.join(\"data\", \"BerkeleySegmentationDataset\")\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "#folder with images to be evaluated\n",
    "example_folder = os.path.join(data_dir, \"example_images\")\n",
    "if not os.path.exists(example_folder):\n",
    "    os.makedirs(example_folder)\n",
    "\n",
    "#folders with resulting images\n",
    "results_folder = os.path.join(data_dir, \"example_results\")\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "#names of used models\n",
    "model_names = [\"VDSR\", \"DRNN\", \"SRResNet\", \"SRGAN\"]\n",
    "\n",
    "#output dimensions of models respectively (assumed that output is a square)\n",
    "output_dims = [64, 64, 224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename - relative path of image being processed\n",
    "#model - the model for super-resolution\n",
    "#outfile - relative path of the image which will be saved\n",
    "\n",
    "#output_dims - dimensions of current model output image\n",
    "#            - it is assumed that model output image is a square\n",
    "\n",
    "#pre_upscale - if True, image will be upscaled by a specified factor with bicubic interpolation at the start\n",
    "#            - the resulting image then replaces the original one in the next operations\n",
    "#            - if False, that step is skipped\n",
    "#            - this should be set on True for models which are clearing up the image and don't make upscaling by themselves\n",
    "\n",
    "#clear_up - if True, the forwarded image will be cleared up by the model and not upscaled\n",
    "#         - this is important to know because step variables are different then (see code)\n",
    "#         - notice that we exit the function if pre_upscale is True and clear_up false because if image was pre-upscaled,\n",
    "#           it should be cleared up afterwards\n",
    "\n",
    "#residual_model - is the model learning residual image only (the difference between blurry and original patch)?\n",
    "#               - if true, residual is added to the low resolutin image to produce the result\n",
    "#               - otherwise, we only need to scale back the result (see code below)\n",
    "def evaluate(filename, model, outfile, output_dims, pre_upscale = False, clear_up = False, residual_model = False):\n",
    "    img = Image.open(filename)\n",
    "\n",
    "    #upscaling coefficient\n",
    "    coef = 2\n",
    "\n",
    "    #at each step, we will evaluate subpatch (x : x + range_x, y : y + range_y) of original image\n",
    "    #patch by patch, we will resolve the whole image\n",
    "    range_x = output_dims // coef\n",
    "    range_y = output_dims // coef\n",
    "\n",
    "    #how many bounding pixels from resulting patch should be excluded?\n",
    "    #this is important because boundaries tend to be predicted less accurately\n",
    "    offset = output_dims // 10\n",
    "\n",
    "    #after we evaluate a subpatch, how much we move down/right to get the next one\n",
    "    #we subtract offset to cover those pixels which were boundary in the previous subpatch\n",
    "    step_x = range_x - offset\n",
    "    step_y = range_y - offset\n",
    "\n",
    "    #situation which should not occur, if we need preprocess, we will need to clear up the result\n",
    "    if((pre_upscale) and (not clear_up)):\n",
    "        print(\"Pre-magnified image is not being cleared up.\")\n",
    "        return\n",
    "\n",
    "    #pre-magnify picture if needed\n",
    "    if(pre_upscale):\n",
    "        img = img.resize((coef * img.width, coef * img.height), Image.BICUBIC)\n",
    "\n",
    "    #if the current image is being cleared up with no further uspcaling,\n",
    "    #set coef to 1 and other parameters accordingly\n",
    "    if(clear_up):\n",
    "        result = np.zeros((img.height, img.width, 3))\n",
    "        range_x = output_dims\n",
    "        range_y = output_dims\n",
    "        step_x = range_x - 2 * offset\n",
    "        step_y = range_y - 2 * offset\n",
    "        coef = 1\n",
    "    #otherwise, set result to be coef (2 by default) times larger than image\n",
    "    else:\n",
    "        result = np.zeros((coef * img.height, coef * img.width, 3))\n",
    "\n",
    "    rect = np.array(img, dtype = np.float32)\n",
    "\n",
    "    #if the image is too small for some models to work on it, pad it with zeros\n",
    "    if(rect.shape[0] < range_y):\n",
    "        pad = np.zeros((range_y - rect.shape[0], rect.shape[1], rect.shape[2]))\n",
    "        rect = np.concatenate((rect, pad), axis = 0).astype(dtype = np.float32)\n",
    "\n",
    "    if(rect.shape[1] < range_x):\n",
    "        pad = np.zeros((rect.shape[0], range_x - rect.shape[1], rect.shape[2]))\n",
    "        rect = np.concatenate((rect, pad), axis = 1).astype(dtype = np.float32)\n",
    "\n",
    "    x = 0\n",
    "    y = 0\n",
    "\n",
    "    #take subpatch by subpatch and resolve them to get the final image result\n",
    "    while(y < img.width):\n",
    "        x = 0\n",
    "        while(x < img.height):\n",
    "            rgb_patch = rect[x : x + range_x, y : y + range_y]\n",
    "            rgb_patch = rgb_patch[..., [2, 1, 0]]\n",
    "            rgb_patch = np.ascontiguousarray(np.rollaxis(rgb_patch, 2))\n",
    "            pred = np.squeeze(model.eval({model.arguments[0] : [rgb_patch]}))\n",
    "\n",
    "            img1 = np.ascontiguousarray(rgb_patch.transpose(2, 1, 0))\n",
    "            img2 = np.ascontiguousarray(pred.transpose(2, 1, 0))\n",
    "\n",
    "            #if model predicts residual image,\n",
    "            #scale back the prediction and add to starting patch\n",
    "            #otherwise just scale back\n",
    "            if(residual_model):\n",
    "                img2 = 255.0 * img2 + img1\n",
    "            else:\n",
    "                img2 = pred.transpose(2, 1, 0)\n",
    "                img2 = img2 * 255.0\n",
    "\n",
    "            # make sure img2 is C Contiguous as we just transposed it\n",
    "            img2 = np.ascontiguousarray(img2)\n",
    "            #make sure no pixels are outside [0, 255] interval\n",
    "            for _ in range(2):\n",
    "                img2 = C.relu(img2).eval()\n",
    "                img2 = np.ones(img2.shape) * 255.0 - img2\n",
    "\n",
    "            rgb = img2[..., ::-1]\n",
    "            patch = rgb.transpose(1, 0, 2)\n",
    "\n",
    "            #fill in the pixels in the middle of the subpatch\n",
    "            #don't fill those within offset range to the boundary\n",
    "            for h in range(coef * x + offset, coef * x + output_dims - offset):\n",
    "                for w in range(coef * y + offset, coef * y + output_dims - offset):\n",
    "                    for col in range(0, 3):\n",
    "                        result[h][w][col] = patch[h - coef * x][w - coef * y][col]\n",
    "\n",
    "            #pad top\n",
    "            if(x == 0):\n",
    "                for h in range(offset):\n",
    "                    for w in range(coef * y, coef * y + output_dims):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h][w - coef * y][col]\n",
    "\n",
    "            #pad left\n",
    "            if(y == 0):\n",
    "                for h in range(coef * x, coef * x + output_dims):\n",
    "                    for w in range(offset):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h - coef * x][w][col]\n",
    "\n",
    "            #pad bottom\n",
    "            if(x == img.height - range_x):\n",
    "                for h in range(coef * img.height - offset, coef * img.height):\n",
    "                    for w in range(coef * y, coef * y + output_dims):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h - coef * x][w - coef * y][col]\n",
    "\n",
    "            #pad right\n",
    "            if(y == img.width - range_y):\n",
    "                for h in range(coef * x, coef * x + output_dims):\n",
    "                    for w in range(coef * img.width - offset, coef * img.width):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h - coef * x][w - coef * y][col]\n",
    "\n",
    "            #reached bottom of image\n",
    "            if(x == img.height - range_x):\n",
    "                break\n",
    "            #next step by x, we must not go out of bounds\n",
    "            x = min(x + step_x, img.height - range_x)\n",
    "\n",
    "        #reached right edge of image\n",
    "        if(y == img.width - range_x):\n",
    "            break\n",
    "        #next step by y, we must not go out of bounds\n",
    "        y = min(y + step_y, img.width - range_x)\n",
    "\n",
    "    result = np.ascontiguousarray(result)\n",
    "\n",
    "    #save result\n",
    "    imsave(outfile, result.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory data/BerkeleySegmentationDataset/PretrainedModels\n",
      "Image directory data/BerkeleySegmentationDataset/Images\n"
     ]
    }
   ],
   "source": [
    "#Get the path for pre-trained models and example images\n",
    "if is_test():\n",
    "    models_dir = os.path.join(test_data_dir, \"PretrainedModels\")\n",
    "    image_dir = os.path.join(test_data_dir, \"Images\")\n",
    "else:\n",
    "    models_dir = os.path.join(data_dir, \"PretrainedModels\")\n",
    "    if not os.path.exists(models_dir):\n",
    "        os.makedirs(models_dir)\n",
    "\n",
    "    image_dir = os.path.join(data_dir, \"Images\")\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "\n",
    "print(\"Model directory\", models_dir)\n",
    "print(\"Image directory\", image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading VDSR model...\n",
      "Downloading DRNN model...\n",
      "Downloading SRResNet model...\n",
      "Downloading SRGAN model...\n",
      "Loading pretrained models...\n",
      "Loaded pretrained models.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(os.path.join(models_dir, \"VDSR.model\")):\n",
    "    print(\"Downloading VDSR model...\")\n",
    "    urlretrieve(\"https://www.cntk.ai/Models/SuperResolution/VDSR.model\", os.path.join(models_dir, \"VDSR.model\"))\n",
    "else:\n",
    "    print(\"Using cached VDSR model\")\n",
    "\n",
    "if not os.path.isfile(os.path.join(models_dir, \"DRNN.model\")):\n",
    "    print(\"Downloading DRNN model...\")\n",
    "    urlretrieve(\"https://www.cntk.ai/Models/SuperResolution/DRNN.model\", os.path.join(models_dir, \"DRNN.model\"))\n",
    "else:\n",
    "    print(\"Using cached DRNN.model\")\n",
    "\n",
    "if not os.path.isfile(os.path.join(models_dir, \"SRResNet.model\")):\n",
    "    print(\"Downloading SRResNet model...\")\n",
    "    urlretrieve(\"https://www.cntk.ai/Models/SuperResolution/SRResNet.model\", os.path.join(models_dir, \"SRResNet.model\"))\n",
    "else:\n",
    "    print(\"Using cached SRResNet.model\")\n",
    "\n",
    "if not os.path.isfile(os.path.join(models_dir, \"SRGAN.model\")):\n",
    "    print(\"Downloading SRGAN model...\")\n",
    "    urlretrieve(\"https://www.cntk.ai/Models/SuperResolution/SRGAN.model\", os.path.join(models_dir, \"SRGAN.model\"))\n",
    "else:\n",
    "    print(\"Using cached SRGAN model\")\n",
    "\n",
    "print(\"Loading pretrained models...\")\n",
    "VDSR_model = C.load_model(os.path.join(models_dir, \"VDSR.model\"))\n",
    "DRNN_model = C.load_model(os.path.join(models_dir, \"DRNN.model\"))\n",
    "SRResNet_model = C.load_model(os.path.join(models_dir, \"SRResNet.model\"))\n",
    "SRGAN_model = C.load_model(os.path.join(models_dir, \"SRGAN.model\"))\n",
    "\n",
    "models = [VDSR_model, DRNN_model, SRResNet_model, SRGAN_model]\n",
    "\n",
    "print(\"Loaded pretrained models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached image file\n"
     ]
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "if not os.path.isfile(os.path.join(image_dir, \"253027.jpg\")):\n",
    "    print(\"Downloading example image ...\")\n",
    "    link = \"https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/BSDS300/html/images/plain/normal/color/253027.jpg\"\n",
    "    urlretrieve(link, os.path.join(example_folder, \"253027.jpg\"))\n",
    "else:\n",
    "    print(\"Using cached image file\")\n",
    "    copyfile(os.path.join(image_dir, \"253027.jpg\"), os.path.join(example_folder, \"253027.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = os.path.join(results_folder, \"bicubic\")\n",
    "\n",
    "#upscale by bicubic and save for reference\n",
    "for entry in os.listdir(example_folder):\n",
    "    filename = os.path.join(example_folder, entry)\n",
    "\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    img = Image.open(filename)\n",
    "    out = img.resize((2 * img.width, 2 * img.height), Image.BICUBIC)\n",
    "    out.save(os.path.join(save_folder, entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now creating: data/BerkeleySegmentationDataset/example_results/VDSR_results/253027.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/savath/.virtualenvs/wazir/lib/python3.5/site-packages/ipykernel_launcher.py:158: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now creating: data/BerkeleySegmentationDataset/example_results/VDSR_VDSR_results/253027.jpg\n",
      "Now creating: data/BerkeleySegmentationDataset/example_results/DRNN_VDSR_results/253027.jpg\n",
      "Now creating: data/BerkeleySegmentationDataset/example_results/DRNN_results/253027.jpg\n",
      "Now creating: data/BerkeleySegmentationDataset/example_results/VDSR_DRNN_results/253027.jpg\n",
      "Now creating: data/BerkeleySegmentationDataset/example_results/DRNN_DRNN_results/253027.jpg\n",
      "Now creating: data/BerkeleySegmentationDataset/example_results/SRResNet_results/253027.jpg\n",
      "Now creating: data/BerkeleySegmentationDataset/example_results/VDSR_SRResNet_results/253027.jpg\n",
      "Now creating: data/BerkeleySegmentationDataset/example_results/DRNN_SRResNet_results/253027.jpg\n",
      "Now creating: data/BerkeleySegmentationDataset/example_results/SRGAN_results/253027.jpg\n",
      "Now creating: data/BerkeleySegmentationDataset/example_results/VDSR_SRGAN_results/253027.jpg\n",
      "Now creating: data/BerkeleySegmentationDataset/example_results/DRNN_SRGAN_results/253027.jpg\n"
     ]
    }
   ],
   "source": [
    "#loop thorugh every model\n",
    "for i in range(4):\n",
    "    save_folder = os.path.join(results_folder, model_names[i] + \"_results\")\n",
    "\n",
    "    #loop through every image in example_folder\n",
    "    for entry in os.listdir(example_folder):\n",
    "        filename = os.path.join(example_folder, entry)\n",
    "\n",
    "        if not os.path.exists(save_folder):\n",
    "            os.makedirs(save_folder)\n",
    "\n",
    "        outfile = os.path.join(save_folder, entry)\n",
    "\n",
    "        print(\"Now creating: \" + outfile)\n",
    "\n",
    "        #function calls for different models\n",
    "        if(i < 2):\n",
    "            #residual learning, image is pre-upscaled and then cleared up\n",
    "            evaluate(filename, models[i], outfile, output_dims[i], pre_upscale = True, clear_up = True, residual_model = True)\n",
    "        else:\n",
    "            #all upscaling is within the model\n",
    "            evaluate(filename, models[i], outfile, output_dims[i], pre_upscale = False, clear_up = False, residual_model = False)\n",
    "\n",
    "    #loop through models which can additionally clear up image after we increased it (DRNN and VDSR)\n",
    "    for j in range(2):\n",
    "        #loop through results of previously applied model\n",
    "        for entry in os.listdir(save_folder):\n",
    "            filename = os.path.join(save_folder, entry)\n",
    "            filter_folder = os.path.join(results_folder, model_names[j] + \"_\" + model_names[i] + \"_results\")\n",
    "\n",
    "            if not os.path.exists(filter_folder):\n",
    "                os.makedirs(filter_folder)\n",
    "\n",
    "            outfile = os.path.join(filter_folder, entry)\n",
    "\n",
    "            print(\"Now creating: \" + outfile)\n",
    "\n",
    "            #additionally clear up image without pre-magnifying\n",
    "            evaluate(filename, models[j], outfile, output_dims[j], pre_upscale = False, clear_up = True, residual_model = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
